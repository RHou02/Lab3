{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d0c34ca",
      "metadata": {
        "id": "3d0c34ca"
      },
      "source": [
        "# CS 5542 — Lab 3: Multimodal RAG Systems & Retrieval Evaluation  \n",
        "**Text + Images/PDFs (runs offline by default; optional LLM API hook)**\n",
        "\n",
        "This notebook is a **student-ready, simplified, and fully runnable** lab workflow for **multimodal retrieval-augmented generation (RAG)**:\n",
        "- ingest **PDF text** + **image captions/filenames**\n",
        "- retrieve evidence with a lightweight baseline (TF‑IDF)\n",
        "- build a **context block** for answering\n",
        "- evaluate retrieval quality (Precision@5, Recall@10)\n",
        "- run an **ablation study** (REQUIRED)\n",
        "\n",
        "> ✅ **Important:** The code is optimized for **clarity + reproducibility for students** (minimal dependencies, no keys required).  \n",
        "> It is not the “fastest possible” or “best-performing” RAG system — but it is a correct baseline that you can extend.\n",
        "\n",
        "---\n",
        "\n",
        "## Student Tasks (what you must do)\n",
        "1. **Ingest** PDFs + images from `project_data_mm/` (or use the provided sample package).  \n",
        "2. Implement / experiment with **chunking strategies** (page-based vs fixed-size).  \n",
        "3. Compare retrieval methods (at least):  \n",
        "   - **Sparse** (TF‑IDF / BM25-style)  \n",
        "   - **Dense** (optional: embeddings)  \n",
        "   - **Hybrid** (score fusion with `alpha`)  \n",
        "   - **Hybrid + rerank** (optional: reranker / LLM rerank)  \n",
        "4. Build a **multimodal context** that includes **evidence items** (text + images).  \n",
        "5. Produce the required **results table**:\n",
        "\n",
        "`Query × Method × Precision@5 × Recall@10 × Faithfulness`\n",
        "\n",
        "---\n",
        "\n",
        "## Expected Outputs (what graders look for)\n",
        "- Printed ingestion counts (how many PDF pages/chunks, how many images)\n",
        "- A retrieval demo showing **top‑k evidence** for a query\n",
        "- Evaluation metrics per method (P@5, R@10)\n",
        "- An ablation section with a small comparison table + short explanation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "734b5101",
      "metadata": {
        "id": "734b5101"
      },
      "source": [
        "## Key Parameters You Can Tune (and what they do)\n",
        "\n",
        "These parameters control retrieval + context building. **Students should change them and report what happens.**\n",
        "\n",
        "- **`TOP_K_TEXT`**: how many text chunks to consider as candidates.  \n",
        "  - Larger → more recall, but more noise (lower precision).\n",
        "- **`TOP_K_IMAGES`**: how many image items to consider as candidates.  \n",
        "  - Larger → more multimodal evidence, but can add irrelevant images.\n",
        "- **`TOP_K_EVIDENCE`**: how many total evidence items (text+image) go into the final context.  \n",
        "  - Larger → longer context; may dilute answer quality.\n",
        "- **`ALPHA`** *(0 → 1)*: **fusion weight** when mixing text vs image evidence.  \n",
        "  - `ALPHA = 1.0` → text dominates  \n",
        "  - `ALPHA = 0.0` → images dominate  \n",
        "  - typical starting point: `0.5`\n",
        "- **`CHUNK_SIZE`** (fixed-size chunking): characters per chunk (baseline).  \n",
        "  - Smaller → more granular retrieval (often higher precision)  \n",
        "  - Larger → fewer chunks (often higher recall but less specific)\n",
        "- **`CHUNK_OVERLAP`**: overlap between chunks to avoid cutting important info.  \n",
        "  - Too high → redundant chunks; too low → missing context boundaries\n",
        "\n",
        "### What to try (recommended student experiments)\n",
        "- Keep everything fixed, vary **`ALPHA`**: 0.2, 0.5, 0.8  \n",
        "- Vary **`TOP_K_TEXT`**: 2, 5, 10  \n",
        "- Compare **page-based** vs **fixed-size** chunking (required ablation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fa6fe39",
      "metadata": {
        "id": "5fa6fe39"
      },
      "source": [
        "## 0) Student Info (Fill in)\n",
        "- Name: Ruixuan Hou\n",
        "- UMKC ID: 16367969\n",
        "- Course/Section: CS5542-0001\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "311e0454",
      "metadata": {
        "id": "311e0454"
      },
      "source": [
        "## 1) Setup (student-friendly baseline)\n",
        "\n",
        "This lab starter is designed to be **easy to run** and **easy to modify**:\n",
        "- **PyMuPDF (`fitz`)** for PDF text extraction\n",
        "- **scikit-learn** for TF‑IDF retrieval (strong sparse baseline)\n",
        "- **Pillow** for basic image IO\n",
        "- Optional: connect an **LLM API** for answer generation (not required to run retrieval + eval)\n",
        "\n",
        "### Student guideline\n",
        "- First make sure **retrieval + metrics** run end-to-end.\n",
        "- Then iterate: chunking → retrieval method → fusion (`ALPHA`) → rerank → faithfulness.\n",
        "\n",
        "> If you have API keys (e.g., Gemini / OpenAI / etc.), you can plug them into the optional LLM hook later —  \n",
        "> but your retrieval evaluation should work **without** any external keys.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "25b3d405",
      "metadata": {
        "id": "25b3d405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5229916-6306-4bba-b86c-8045c94d1496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.7\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os, re, glob, json, math\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!pip install PyMuPDF\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tGZPHCy-13Jm"
      },
      "id": "tGZPHCy-13Jm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d89da50c",
      "metadata": {
        "id": "d89da50c"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Lab Configuration (EDIT ME)\n",
        "# =========================\n",
        "# Students: try changing these and observe how retrieval metrics change.\n",
        "\n",
        "DATA_DIR = \"project_data_mm\"   # folder containing pdfs/ and figures/ ; I changed to expected structure as below\n",
        "PDF_DIR  = DATA_DIR\n",
        "IMG_DIR  = os.path.join(DATA_DIR, \"figures\")\n",
        "\n",
        "# Retrieval knobs\n",
        "TOP_K_TEXT     = 5    # candidate text chunks\n",
        "TOP_K_IMAGES   = 3    # candidate images (based on captions/filenames)\n",
        "TOP_K_EVIDENCE = 8    # final evidence items used in the context\n",
        "\n",
        "# Fusion knob (text vs images)\n",
        "ALPHA = 0.5  # 0.0 = images dominate, 1.0 = text dominates\n",
        "\n",
        "# Chunking knobs (for fixed-size chunking ablation)\n",
        "CHUNK_SIZE    = 900   # characters per chunk\n",
        "CHUNK_OVERLAP = 150   # overlap characters\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_SEED = 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a073bd3a",
      "metadata": {
        "id": "a073bd3a"
      },
      "source": [
        "## 2) Data folder\n",
        "Expected structure:\n",
        "```\n",
        "project_data_mm/\n",
        "  doc1.pdf\n",
        "  doc2.pdf\n",
        "  figures/\n",
        "    img1.png\n",
        "    ... (>=5)\n",
        "```\n",
        "![图片.png](data:image/png;base64,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)\n",
        "\n",
        "My folder structure is as above.\n",
        "\n",
        "If the folder is missing, we will generate **sample PDFs and images** automatically so you can run and verify the pipeline end-to-end.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"backup\", ignore_errors=True)\n",
        "print(\"empty\")\n",
        "\n"
      ],
      "metadata": {
        "id": "g9_UioDRucr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f4d085-bbaa-49f5-e8a4-7cfc223ff972"
      },
      "id": "g9_UioDRucr4",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "DATA_DIR = \"project_data_mm\"\n",
        "FIG_DIR = os.path.join(DATA_DIR, \"figures\")\n",
        "\n",
        "pdfs = sorted(glob.glob(os.path.join(DATA_DIR, \"*.pdf\")))\n",
        "imgs = sorted(glob.glob(os.path.join(FIG_DIR, \"*.*\")))\n",
        "\n",
        "print(\"PDF:\", pdfs)\n",
        "print(\"IMG:\", imgs)\n",
        "print(\"PDFs now:\", pdfs)\n",
        "print(\"Images now:\", imgs)\n",
        "\n",
        "# I named my own folder project_data_mm too, so I will run this cell only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyFJgqA_s15M",
        "outputId": "ebda9083-c3de-44de-b60e-567ca79b583c"
      },
      "id": "MyFJgqA_s15M",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF: ['project_data_mm/lease_template_1.pdf', 'project_data_mm/lease_template_2.pdf']\n",
            "IMG: ['project_data_mm/figures/f1.PNG', 'project_data_mm/figures/f2.PNG', 'project_data_mm/figures/f3.PNG', 'project_data_mm/figures/f4.PNG', 'project_data_mm/figures/f5.PNG']\n",
            "PDFs now: ['project_data_mm/lease_template_1.pdf', 'project_data_mm/lease_template_2.pdf']\n",
            "Images now: ['project_data_mm/figures/f1.PNG', 'project_data_mm/figures/f2.PNG', 'project_data_mm/figures/f3.PNG', 'project_data_mm/figures/f4.PNG', 'project_data_mm/figures/f5.PNG']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfcc3c6d",
      "metadata": {
        "id": "dfcc3c6d"
      },
      "outputs": [],
      "source": [
        "!pip install reportlab\n",
        "\n",
        "# Data paths\n",
        "DATA_DIR = \"project_data_mm\"\n",
        "FIG_DIR = os.path.join(DATA_DIR, \"figures\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "def _write_sample_pdf(pdf_path: str, title: str, paragraphs: List[str]) -> None:\n",
        "    \"\"\"Create a simple multi-page PDF with ReportLab.\"\"\"\n",
        "    from reportlab.lib.pagesizes import letter\n",
        "    from reportlab.pdfgen import canvas\n",
        "\n",
        "    c = canvas.Canvas(pdf_path, pagesize=letter)\n",
        "    width, height = letter\n",
        "    y = height - 72\n",
        "\n",
        "    c.setFont(\"Helvetica-Bold\", 16)\n",
        "    c.drawString(72, y, title)\n",
        "    y -= 36\n",
        "    c.setFont(\"Helvetica\", 11)\n",
        "\n",
        "    for p in paragraphs:\n",
        "        # naive line wrapping\n",
        "        words = p.split()\n",
        "        line = \"\"\n",
        "        for w in words:\n",
        "            if len(line) + len(w) + 1 > 95:\n",
        "                c.drawString(72, y, line)\n",
        "                y -= 14\n",
        "                line = w\n",
        "                if y < 72:\n",
        "                    c.showPage()\n",
        "                    y = height - 72\n",
        "                    c.setFont(\"Helvetica\", 11)\n",
        "            else:\n",
        "                line = (line + \" \" + w).strip()\n",
        "        if line:\n",
        "            c.drawString(72, y, line)\n",
        "            y -= 18\n",
        "\n",
        "        if y < 72:\n",
        "            c.showPage()\n",
        "            y = height - 72\n",
        "            c.setFont(\"Helvetica\", 11)\n",
        "\n",
        "    c.save()\n",
        "\n",
        "def _write_sample_image(img_path: str, label: str, size=(900, 550)) -> None:\n",
        "    \"\"\"Create a simple image with a big label. Useful for verifying image ingestion.\"\"\"\n",
        "    img = Image.new(\"RGB\", size, (245, 245, 245))\n",
        "    d = ImageDraw.Draw(img)\n",
        "\n",
        "    # Try a default font; if not available, PIL will fall back.\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"DejaVuSans.ttf\", 48)\n",
        "    except Exception:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    d.rectangle([30, 30, size[0]-30, size[1]-30], outline=(30, 30, 30), width=6)\n",
        "    d.text((60, 200), label, fill=(20, 20, 20), font=font)\n",
        "    img.save(img_path)\n",
        "\n",
        "def ensure_sample_dataset(min_pdfs=2, min_imgs=5) -> None:\n",
        "    \"\"\"Create a small dataset if user doesn't have one yet.\"\"\"\n",
        "    pdfs = sorted(glob.glob(os.path.join(DATA_DIR, \"*.pdf\")))\n",
        "    imgs = sorted(glob.glob(os.path.join(FIG_DIR, \"*.*\")))\n",
        "\n",
        "    if len(pdfs) >= min_pdfs and len(imgs) >= min_imgs:\n",
        "        print(\"✅ Found existing dataset:\", len(pdfs), \"PDFs and\", len(imgs), \"images.\")\n",
        "        return\n",
        "\n",
        "    print(\"⚠️ Dataset incomplete. Creating sample dataset...\")\n",
        "\n",
        "    # PDFs\n",
        "    pdf1 = os.path.join(DATA_DIR, \"sample_doc_rag_basics.pdf\")\n",
        "    pdf2 = os.path.join(DATA_DIR, \"sample_doc_multimodal_eval.pdf\")\n",
        "\n",
        "    p1 = [\n",
        "        \"Retrieval-Augmented Generation (RAG) combines a retriever and a generator. The retriever fetches evidence chunks from documents.\",\n",
        "        \"A common baseline is TF-IDF retrieval. Another baseline is BM25, which uses term frequency and inverse document frequency.\",\n",
        "        \"Good RAG answers should be grounded in the retrieved evidence and should not hallucinate facts that are not supported.\",\n",
        "        \"When evidence is missing, the system should say 'I don't know' or request more context.\",\n",
        "    ]\n",
        "    p2 = [\n",
        "        \"Multimodal RAG includes both text (PDF pages) and images (figures). A simple approach is to attach relevant figures as evidence.\",\n",
        "        \"Evaluation can include retrieval metrics such as Precision@k and Recall@k, plus qualitative checks for faithfulness.\",\n",
        "        \"Ablation studies vary the chunking strategy, retriever type, or the number of retrieved items.\",\n",
        "        \"Rubrics help define what counts as relevant evidence for each query.\",\n",
        "    ]\n",
        "\n",
        "    _write_sample_pdf(pdf1, \"Sample Doc 1: RAG Basics\", p1)\n",
        "    _write_sample_pdf(pdf2, \"Sample Doc 2: Multimodal RAG + Evaluation\", p2)\n",
        "\n",
        "    # Images (named so text-based retrieval can match them)\n",
        "    labels = [\n",
        "        \"figure_rag_pipeline\",\n",
        "        \"figure_tfidf_retrieval\",\n",
        "        \"figure_bm25_baseline\",\n",
        "        \"figure_precision_recall\",\n",
        "        \"figure_ablation_study\",\n",
        "    ]\n",
        "    for lab in labels:\n",
        "        _write_sample_image(os.path.join(FIG_DIR, f\"{lab}.png\"), lab)\n",
        "\n",
        "    print(\"✅ Sample dataset created.\")\n",
        "\n",
        "ensure_sample_dataset()\n",
        "\n",
        "pdfs = sorted(glob.glob(os.path.join(DATA_DIR, \"*.pdf\")))\n",
        "imgs = sorted(glob.glob(os.path.join(FIG_DIR, \"*.*\")))\n",
        "\n",
        "print(\"PDFs:\", len(pdfs), pdfs)\n",
        "print(\"Images:\", len(imgs), imgs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb5e694",
      "metadata": {
        "id": "2eb5e694"
      },
      "source": [
        "## 3) Define your 3 queries + rubrics\n",
        "**Guideline:** write queries that can be answered using your PDFs/images.\n",
        "\n",
        "Rubric format below is **simple and runnable**:\n",
        "- `must_have_keywords`: words/phrases that should appear in relevant evidence\n",
        "- `optional_keywords`: nice-to-have\n",
        "\n",
        "Later, retrieval metrics will treat an evidence chunk as relevant if it contains at least one `must_have_keywords` item.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "80ccdf82",
      "metadata": {
        "id": "80ccdf82"
      },
      "outputs": [],
      "source": [
        "QUERIES = [\n",
        "    {\n",
        "        \"id\": \"Q1\",\n",
        "        \"question\": \"What are the rent amount and late fee policy in this lease agreement?\",\n",
        "        \"rubric\": {\n",
        "            \"must_have_keywords\": [\"rent\", \"late fee\", \"per month\", \"$\", \"grace period\"],\n",
        "            \"optional_keywords\": [\"payment\", \"due\", \"monthly\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"Q2\",\n",
        "        \"question\": \"What rules apply to pets and are there any additional fees?\",\n",
        "        \"rubric\": {\n",
        "            \"must_have_keywords\": [\"pets\", \"pet\", \"permission\", \"fee\", \"pet-rent\"],\n",
        "            \"optional_keywords\": [\"cleaning\", \"deposit\", \"animals\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"Q3\",\n",
        "        \"question\": \"Does the contract mention interest paid on the security deposit?\",\n",
        "        \"rubric\": {\n",
        "            \"must_have_keywords\": [\"security deposit\", \"interest\"],\n",
        "            \"optional_keywords\": [\"refund\", \"deposit\"]\n",
        "        }\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ddd9add",
      "metadata": {
        "id": "5ddd9add"
      },
      "source": [
        "## 4) Ingestion\n",
        "We extract:\n",
        "- **PDF per-page text** as `TextChunk`\n",
        "- **Image metadata** as `ImageItem` (caption = filename without extension)\n",
        "\n",
        "> This is intentionally lightweight so it runs without downloading large embedding models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "560eb7b7",
      "metadata": {
        "id": "560eb7b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1f3ea4-256d-41ec-d9a1-0ca85bd995ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total text chunks: 18\n",
            "Total images: 5\n",
            "Sample text chunk: lease_template_1.pdf::p1 STANDARD RESIDENTIAL LEASE AGREEMENT 1. THE PARTIES. This Residential Lease Agreement (“Agreement”) is made on the undersigned date by and between: Landlord Landlord's Name: [LANDL\n",
            "Sample image item: ImageItem(item_id='f1.PNG', path='project_data_mm/figures/f1.PNG', caption='f1')\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class TextChunk:\n",
        "    chunk_id: str\n",
        "    doc_id: str\n",
        "    page_num: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ImageItem:\n",
        "    item_id: str\n",
        "    path: str\n",
        "    caption: str  # simple text to make image retrieval runnable\n",
        "\n",
        "def clean_text(s: str) -> str:\n",
        "    s = s or \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def extract_pdf_pages(pdf_path: str) -> List[TextChunk]:\n",
        "    doc_id = os.path.basename(pdf_path)\n",
        "    doc = fitz.open(pdf_path)\n",
        "    out: List[TextChunk] = []\n",
        "    for i in range(len(doc)):\n",
        "        page = doc.load_page(i)\n",
        "        text = clean_text(page.get_text(\"text\"))\n",
        "        if text:\n",
        "            out.append(TextChunk(\n",
        "                chunk_id=f\"{doc_id}::p{i+1}\",\n",
        "                doc_id=doc_id,\n",
        "                page_num=i+1,\n",
        "                text=text\n",
        "            ))\n",
        "    return out\n",
        "\n",
        "def load_images(fig_dir: str) -> List[ImageItem]:\n",
        "    items: List[ImageItem] = []\n",
        "    for p in sorted(glob.glob(os.path.join(fig_dir, \"*.*\"))):\n",
        "        base = os.path.basename(p)\n",
        "        caption = os.path.splitext(base)[0].replace(\"_\", \" \")\n",
        "        items.append(ImageItem(item_id=base, path=p, caption=caption))\n",
        "    return items\n",
        "\n",
        "# Run ingestion\n",
        "page_chunks: List[TextChunk] = []\n",
        "for p in pdfs:\n",
        "    page_chunks.extend(extract_pdf_pages(p))\n",
        "\n",
        "image_items = load_images(FIG_DIR)\n",
        "\n",
        "print(\"Total text chunks:\", len(page_chunks))\n",
        "print(\"Total images:\", len(image_items))\n",
        "print(\"Sample text chunk:\", page_chunks[0].chunk_id, page_chunks[0].text[:180])\n",
        "print(\"Sample image item:\", image_items[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf833eaf",
      "metadata": {
        "id": "cf833eaf"
      },
      "source": [
        "## 5) Retrieval (TF‑IDF)\n",
        "We build two TF‑IDF indexes:\n",
        "- One over **PDF text chunks**\n",
        "- One over **image captions**\n",
        "\n",
        "Retrieval returns the top‑k results with similarity scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9fde54d",
      "metadata": {
        "id": "f9fde54d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d0efdb-6e1a-4354-e5ce-67e096f62399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Indexes built.\n"
          ]
        }
      ],
      "source": [
        "def build_tfidf_index_text(chunks: List[TextChunk]):\n",
        "    corpus = [c.text for c in chunks]\n",
        "    vec = TfidfVectorizer(lowercase=True, stop_words=\"english\")\n",
        "    X = vec.fit_transform(corpus)\n",
        "    X = normalize(X)\n",
        "    return vec, X\n",
        "\n",
        "def build_tfidf_index_images(items: List[ImageItem]):\n",
        "    corpus = [it.caption for it in items]\n",
        "    vec = TfidfVectorizer(lowercase=True, stop_words=\"english\")\n",
        "    X = vec.fit_transform(corpus)\n",
        "    X = normalize(X)\n",
        "    return vec, X\n",
        "\n",
        "text_vec, text_X = build_tfidf_index_text(page_chunks)\n",
        "img_vec, img_X = build_tfidf_index_images(image_items)\n",
        "\n",
        "def tfidf_retrieve(query: str, vec: TfidfVectorizer, X, top_k: int = 5):\n",
        "    q = vec.transform([query])\n",
        "    q = normalize(q)\n",
        "    scores = (X @ q.T).toarray().ravel()\n",
        "    idx = np.argsort(-scores)[:top_k]\n",
        "    return [(int(i), float(scores[i])) for i in idx]\n",
        "\n",
        "print(\"✅ Indexes built.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d14a7a9b",
      "metadata": {
        "id": "d14a7a9b"
      },
      "source": [
        "## 6) Build evidence context\n",
        "We assemble a compact context string + list of image paths.\n",
        "\n",
        "**Guidelines for good context:**\n",
        "- Keep snippets short (100–300 chars)\n",
        "- Always include chunk IDs so you can cite evidence\n",
        "- Attach images that are likely relevant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "14f595da",
      "metadata": {
        "id": "14f595da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64383e71-b86f-4224-c59e-9428da38016e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEXT | lease_template_1.pdf::p2 | fused=0.500] 5. SECURITY DEPOSIT. (check one) ☐ - No Security Deposit. ☐ - Security Deposit. • Amount: $[AMOUNT] • Returning to Tenant: [#] days after lease termination. 6. LATE FEE. (check one) ☐ - No Late Fee. ☐ - Late Fee: (check one) ☐ - Fixed Amount. $[AMOUNT] for eac\n",
            "[IMAGE | f1.PNG | fused=0.500] caption=f1\n",
            "[IMAGE | f2.PNG | fused=0.500] caption=f2\n",
            "[IMAGE | f3.PNG | fused=0.500] caption=f3\n",
            "[TEXT | lease_template_2.pdf::p1 | fused=0.127] Teacher Resources for Consumer.gov | Developed for the FTC by the Center for Applied Linguistics SAMPLE RENTAL AGREEMENT (Basic / Beginning) THIS AGREEMENT made this 15th Day of June, 2012, by and between ABC Properties, herein called “Landlord,” and Silvia Ma\n",
            "[TEXT | lease_template_1.pdf::p9 | fused=0.032] n.) Pets. If any property repairs, odor removal, or other maintenance is required due to the Tenant’s Pets, the costs shall be deducted from the Pet Fee or Security Deposit with an itemized list disclosed to the Tenant. i. Pet Restrictions. Any pet restriction\n",
            "[TEXT | lease_template_1.pdf::p8 | fused=0.017] b.) Access. Upon the start of the Early Move-In or the Term, whichever is applicable, the Landlord agrees to provide entry to the Tenant in the form of keys, fobs, cards, or any type of keyless access to the Property. Access to the Property shall be given afte\n",
            "[TEXT | lease_template_1.pdf::p1 | fused=0.000] STANDARD RESIDENTIAL LEASE AGREEMENT 1. THE PARTIES. This Residential Lease Agreement (“Agreement”) is made on the undersigned date by and between: Landlord Landlord's Name: [LANDLORD'S NAME] Mailing Address: [LANDLORD'S ADDRESS] Tenant Tenant’s Name: [TENANT'\n",
            "Images: ['project_data_mm/figures/f1.PNG', 'project_data_mm/figures/f2.PNG', 'project_data_mm/figures/f3.PNG']\n",
            "Fusion alpha: 0.5\n"
          ]
        }
      ],
      "source": [
        "def _normalize_scores(pairs):\n",
        "    \"\"\"Min-max normalize a list of (idx, score) to [0,1].\n",
        "    If all scores equal, returns 1.0 for each item (so ordering stays stable).\n",
        "    \"\"\"\n",
        "    if not pairs:\n",
        "        return []\n",
        "    scores = [s for _, s in pairs]\n",
        "    lo, hi = min(scores), max(scores)\n",
        "    if abs(hi - lo) < 1e-12:\n",
        "        return [(i, 1.0) for i, _ in pairs]\n",
        "    return [(i, (s - lo) / (hi - lo)) for i, s in pairs]\n",
        "\n",
        "\n",
        "def build_context(\n",
        "    question: str,\n",
        "    top_k_text: int = TOP_K_TEXT,\n",
        "    top_k_images: int = TOP_K_IMAGES,\n",
        "    top_k_evidence: int = TOP_K_EVIDENCE,\n",
        "    alpha: float = ALPHA,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Build a multimodal context block for the question.\n",
        "\n",
        "    Students:\n",
        "    - `top_k_text` / `top_k_images` control *candidate retrieval* per modality.\n",
        "    - `top_k_evidence` controls the *final context size*.\n",
        "    - `alpha` controls fusion: higher = prefer text evidence, lower = prefer images.\n",
        "\n",
        "    This function returns:\n",
        "    - `context`: a text block with the selected evidence (what you pass to an LLM)\n",
        "    - `image_paths`: paths of images selected as evidence\n",
        "    - `evidence`: structured evidence list (recommended for your report)\n",
        "    \"\"\"\n",
        "    # 1) Retrieve candidates from each modality\n",
        "    text_hits = tfidf_retrieve(question, text_vec, text_X, top_k=top_k_text)   # [(idx, score), ...]\n",
        "    img_hits  = tfidf_retrieve(question, img_vec,  img_X,  top_k=top_k_images)\n",
        "\n",
        "    # 2) Normalize scores per modality and fuse with ALPHA\n",
        "    text_norm = _normalize_scores(text_hits)\n",
        "    img_norm  = _normalize_scores(img_hits)\n",
        "\n",
        "    fused = []\n",
        "    for idx, s in text_norm:\n",
        "        ch = page_chunks[idx]\n",
        "        fused.append({\n",
        "            \"modality\": \"text\",\n",
        "            \"id\": ch.chunk_id,\n",
        "            \"raw_score\": float(dict(text_hits).get(idx, 0.0)),\n",
        "            \"fused_score\": float(alpha * s),\n",
        "            \"text\": ch.text,\n",
        "            \"path\": None,\n",
        "        })\n",
        "\n",
        "    for idx, s in img_norm:\n",
        "        it = image_items[idx]\n",
        "        fused.append({\n",
        "            \"modality\": \"image\",\n",
        "            \"id\": it.item_id,\n",
        "            \"raw_score\": float(dict(img_hits).get(idx, 0.0)),\n",
        "            \"fused_score\": float((1.0 - alpha) * s),\n",
        "            \"text\": it.caption,     # we retrieve on caption/filename text\n",
        "            \"path\": it.path,\n",
        "        })\n",
        "\n",
        "    # 3) Pick top fused evidence\n",
        "    fused = sorted(fused, key=lambda d: d[\"fused_score\"], reverse=True)[:top_k_evidence]\n",
        "\n",
        "    # 4) Build the context string (what you feed into a generator/LLM)\n",
        "    ctx_lines = []\n",
        "    image_paths = []\n",
        "    for ev in fused:\n",
        "        if ev[\"modality\"] == \"text\":\n",
        "            snippet = (ev[\"text\"] or \"\")[:260].replace(\"\\n\", \" \")\n",
        "            ctx_lines.append(f\"[TEXT | {ev['id']} | fused={ev['fused_score']:.3f}] {snippet}\")\n",
        "        else:\n",
        "            ctx_lines.append(f\"[IMAGE | {ev['id']} | fused={ev['fused_score']:.3f}] caption={ev['text']}\")\n",
        "            image_paths.append(ev[\"path\"])\n",
        "\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"context\": \"\\n\".join(ctx_lines),\n",
        "        \"image_paths\": image_paths,\n",
        "        \"text_hits\": text_hits,\n",
        "        \"img_hits\": img_hits,\n",
        "        \"evidence\": fused,\n",
        "        \"alpha\": alpha,\n",
        "        \"top_k_text\": top_k_text,\n",
        "        \"top_k_images\": top_k_images,\n",
        "        \"top_k_evidence\": top_k_evidence,\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Demo: what retrieval returns for one query ---\n",
        "ctx_demo = build_context(QUERIES[0][\"question\"])\n",
        "print(ctx_demo[\"context\"])\n",
        "print(\"Images:\", ctx_demo[\"image_paths\"])\n",
        "print(\"Fusion alpha:\", ctx_demo[\"alpha\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "373612a5",
      "metadata": {
        "id": "373612a5"
      },
      "source": [
        "## 7) “Generator” (simple, offline)\n",
        "To keep this notebook runnable anywhere, we implement a **lightweight extractive generator**:\n",
        "- It returns the top evidence lines\n",
        "- In your real submission, you can replace this with an LLM call (HF local model or an API)\n",
        "\n",
        "**Key rule:** the answer must stay consistent with evidence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a34c57e9",
      "metadata": {
        "id": "a34c57e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c06f8c6-58d0-4125-8175-e8bfad6c87e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Q1 What are the rent amount and late fee policy in this lease agreement?\n",
            "Question: What are the rent amount and late fee policy in this lease agreement?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | lease_template_1.pdf::p2 | fused=0.500] 5. SECURITY DEPOSIT. (check one) ☐ - No Security Deposit. ☐ - Security Deposit. • Amount: $[AMOUNT] • Returning to Tenant: [#] days after lease termination. 6. LATE FEE. (check one) ☐ - No Late Fee. ☐ - Late Fee: (check one) ☐ - Fixed Amount. $[AMOUNT] for eac\n",
            "[IMAGE | f1.PNG | fused=0.500] caption=f1\n",
            "Images: ['f1.PNG', 'f2.PNG', 'f3.PNG']\n",
            "\n",
            "================================================================================\n",
            "Q2 What rules apply to pets and are there any additional fees?\n",
            "Question: What rules apply to pets and are there any additional fees?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | lease_template_1.pdf::p4 | fused=0.500] ☐ - No Pets Allowed. ☐ - Pets are Allowed. Number of Pets: [#] Types: [PET TYPES] Maximum Weight (per pet): [#] Pounds Deposit (for all pets): $[AMOUNT] ☐ refundable ☐ non-refundable 12. SMOKING POLICY. (check one) ☐ - No Smoking Allowed. ☐ - Smoking is Allowe\n",
            "[IMAGE | f1.PNG | fused=0.500] caption=f1\n",
            "Images: ['f1.PNG', 'f2.PNG', 'f3.PNG']\n",
            "\n",
            "================================================================================\n",
            "Q3 Does the contract mention interest paid on the security deposit?\n",
            "Question: Does the contract mention interest paid on the security deposit?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | lease_template_1.pdf::p10 | fused=0.500] duration of the Term and any renewals thereof. Failure to maintain the required insurance constitutes a breach of this Agreement and may result in termination of tenancy and eviction under local housing laws. iv. Landlord’s Insurance. Tenant acknowledges that \n",
            "[IMAGE | f1.PNG | fused=0.500] caption=f1\n",
            "Images: ['f1.PNG', 'f2.PNG', 'f3.PNG']\n"
          ]
        }
      ],
      "source": [
        "def simple_extractive_answer(question: str, context: str) -> str:\n",
        "    lines = context.splitlines()\n",
        "    if not lines:\n",
        "        return \"I don't know (no evidence retrieved).\"\n",
        "    # Return top 2 evidence lines as a \"grounded\" answer\n",
        "    return (\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Grounded answer (extractive):\\n\"\n",
        "        + \"\\n\".join(lines[:2])\n",
        "    )\n",
        "\n",
        "def run_query(qobj, top_k_text=TOP_K_TEXT, top_k_images=TOP_K_IMAGES, top_k_evidence=TOP_K_EVIDENCE, alpha=ALPHA) -> Dict[str, Any]:\n",
        "    question = qobj[\"question\"]\n",
        "    ctx = build_context(question, top_k_text=top_k_text, top_k_images=top_k_images, top_k_evidence=top_k_evidence, alpha=alpha)\n",
        "    answer = simple_extractive_answer(question, ctx[\"context\"])\n",
        "    return {\n",
        "        \"id\": qobj[\"id\"],\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"context\": ctx[\"context\"],\n",
        "        \"image_paths\": ctx[\"image_paths\"],\n",
        "        \"text_hits\": ctx[\"text_hits\"],\n",
        "        \"img_hits\": ctx[\"img_hits\"],\n",
        "    }\n",
        "\n",
        "results = [run_query(q) for q in QUERIES]\n",
        "for r in results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(r[\"id\"], r[\"question\"])\n",
        "    print(r[\"answer\"][:500])\n",
        "    print(\"Images:\", [os.path.basename(p) for p in r[\"image_paths\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a4ba05a",
      "metadata": {
        "id": "9a4ba05a"
      },
      "source": [
        "## 8) Retrieval Evaluation (Precision@k / Recall@k)\n",
        "We treat a text chunk as **relevant** for a query if it contains at least one `must_have_keywords` term.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2d16c336",
      "metadata": {
        "id": "2d16c336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "a0bfe41a-b1fe-49df-e104-1e1c3b9022a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  P@5      R@10  total_relevant_chunks\n",
              "0  Q1  1.0  0.600000                     15\n",
              "1  Q2  0.8  0.545455                     11\n",
              "2  Q3  0.8  1.000000                      8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9d504b0-3419-47c4-b3a3-eb4f06ce541a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>P@5</th>\n",
              "      <th>R@10</th>\n",
              "      <th>total_relevant_chunks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9d504b0-3419-47c4-b3a3-eb4f06ce541a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9d504b0-3419-47c4-b3a3-eb4f06ce541a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9d504b0-3419-47c4-b3a3-eb4f06ce541a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_a67c6014-53e8-458d-8bed-8a2287f9695a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_eval')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a67c6014-53e8-458d-8bed-8a2287f9695a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_eval');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_eval",
              "summary": "{\n  \"name\": \"df_eval\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P@5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11547005383792512,\n        \"min\": 0.8,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R@10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24818903308416088,\n        \"min\": 0.5454545454545454,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6,\n          0.5454545454545454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_relevant_chunks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 8,\n        \"max\": 15,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          15,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "def is_relevant_text(chunk_text: str, rubric: Dict[str, Any]) -> bool:\n",
        "    text = chunk_text.lower()\n",
        "    must = [k.lower() for k in rubric.get(\"must_have_keywords\", [])]\n",
        "    return any(k in text for k in must)\n",
        "\n",
        "def precision_at_k(relevances: List[bool], k: int) -> float:\n",
        "    k = min(k, len(relevances))\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    return sum(relevances[:k]) / k\n",
        "\n",
        "def recall_at_k(relevances: List[bool], k: int, total_relevant: int) -> float:\n",
        "    k = min(k, len(relevances))\n",
        "    if total_relevant == 0:\n",
        "        return 0.0\n",
        "    return sum(relevances[:k]) / total_relevant\n",
        "\n",
        "def eval_retrieval_for_query(qobj, top_k=10) -> Dict[str, Any]:\n",
        "    question = qobj[\"question\"]\n",
        "    rubric = qobj[\"rubric\"]\n",
        "\n",
        "    hits = tfidf_retrieve(question, text_vec, text_X, top_k=top_k)\n",
        "    rels = []\n",
        "    for i, score in hits:\n",
        "        rels.append(is_relevant_text(page_chunks[i].text, rubric))\n",
        "\n",
        "    # Estimate total relevant in the corpus (for recall)\n",
        "    total_rel = sum(is_relevant_text(ch.text, rubric) for ch in page_chunks)\n",
        "\n",
        "    return {\n",
        "        \"id\": qobj[\"id\"],\n",
        "        \"P@5\": precision_at_k(rels, 5),\n",
        "        \"R@10\": recall_at_k(rels, 10, total_rel),\n",
        "        \"total_relevant_chunks\": total_rel,\n",
        "    }\n",
        "\n",
        "eval_rows = [eval_retrieval_for_query(q) for q in QUERIES]\n",
        "df_eval = pd.DataFrame(eval_rows)\n",
        "df_eval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kT_Nr7NhNdmI"
      },
      "id": "kT_Nr7NhNdmI"
    },
    {
      "cell_type": "markdown",
      "id": "de705dbf",
      "metadata": {
        "id": "de705dbf"
      },
      "source": [
        "## 9) Ablation Study (REQUIRED)\n",
        "\n",
        "You must compare **at least**:\n",
        "- **Chunking A (page-based)** vs **Chunking B (fixed-size)**  \n",
        "- **Sparse** vs **Dense** vs **Hybrid** vs **Hybrid + Rerank** *(dense/rerank can be optional extensions — but include at least sparse + one fusion variant)*  \n",
        "- **Text-only RAG** vs **Multimodal RAG** (your context must include evidence items)\n",
        "\n",
        "**Deliverable:** include a final results table in your README:\n",
        "\n",
        "`Query × Method × Precision@5 × Recall@10 × Faithfulness`\n",
        "\n",
        "### Quick ablation ideas\n",
        "- Vary `TOP_K_TEXT`: 2, 5, 10  \n",
        "- Vary `ALPHA`: 0.2, 0.5, 0.8  \n",
        "- Compare page-chunking vs fixed-size (`CHUNK_SIZE` / `CHUNK_OVERLAP`)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d8b191c1",
      "metadata": {
        "id": "d8b191c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "b0bdbfcf-c29b-4e5f-8e03-52ed4228da16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  top_k_text  P@5      R@10  total_relevant_chunks\n",
              "0  Q1           2  1.0  0.600000                     15\n",
              "1  Q1           5  1.0  0.600000                     15\n",
              "2  Q1          10  1.0  0.600000                     15\n",
              "3  Q2           2  0.8  0.545455                     11\n",
              "4  Q2           5  0.8  0.545455                     11\n",
              "5  Q2          10  0.8  0.545455                     11\n",
              "6  Q3           2  0.8  1.000000                      8\n",
              "7  Q3           5  0.8  1.000000                      8\n",
              "8  Q3          10  0.8  1.000000                      8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4973c536-966a-4966-ab4e-82b0053da01e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>top_k_text</th>\n",
              "      <th>P@5</th>\n",
              "      <th>R@10</th>\n",
              "      <th>total_relevant_chunks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q1</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q1</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q2</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Q3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Q3</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4973c536-966a-4966-ab4e-82b0053da01e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4973c536-966a-4966-ab4e-82b0053da01e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4973c536-966a-4966-ab4e-82b0053da01e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_e3a68c5f-62e6-4d6f-8e70-b2f5128390c6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_ablation')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e3a68c5f-62e6-4d6f-8e70-b2f5128390c6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_ablation');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_ablation",
              "summary": "{\n  \"name\": \"df_ablation\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top_k_text\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          5,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P@5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09999999999999999,\n        \"min\": 0.8,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R@10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21493800759157983,\n        \"min\": 0.5454545454545454,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6,\n          0.5454545454545454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_relevant_chunks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 8,\n        \"max\": 15,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          15,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def ablation_topk_text(qobj, k_list=(2, 5, 10)):\n",
        "    rows = []\n",
        "    for k in k_list:\n",
        "        rows.append({\n",
        "            \"id\": qobj[\"id\"],\n",
        "            \"top_k_text\": k,\n",
        "            **eval_retrieval_for_query(qobj, top_k=max(10, k))  # eval uses top_k hits\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "abl_rows = []\n",
        "for q in QUERIES:\n",
        "    abl_rows.extend(ablation_topk_text(q, k_list=(2, 5, 10)))\n",
        "\n",
        "df_ablation = pd.DataFrame(abl_rows)[[\"id\",\"top_k_text\",\"P@5\",\"R@10\",\"total_relevant_chunks\"]]\n",
        "df_ablation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652c1e2d",
      "metadata": {
        "id": "652c1e2d"
      },
      "source": [
        "## 10) What to submit\n",
        "1) Your updated dataset (or keep your own)\n",
        "2) This notebook (with your answers + screenshots/outputs)\n",
        "3) A short write‑up: retrieval metrics + faithfulness discussion + ablation\n",
        "\n",
        "**Tip:** If you switch to an LLM, keep the same `build_context()` so the evidence is always visible.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}